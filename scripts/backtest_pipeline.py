"""
Comprehensive backtest pipeline for Mizuto.

Usage:
    python scripts/backtest_pipeline.py                    # run all steps
    python scripts/backtest_pipeline.py --step 1           # run a single step
    python scripts/backtest_pipeline.py --step 1 2 3       # run specific steps
    python scripts/backtest_pipeline.py --symbol ETH-USD   # different asset
    python scripts/backtest_pipeline.py --start 2023-01-01 --end 2024-01-01
    python scripts/backtest_pipeline.py --perms 500        # fewer MCPT permutations (faster)
"""

import argparse
import datetime
import os
import sys
import time

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import pandas as pd
import yfinance as yf

from src.backtest import run_backtest_on_data
from src.optimize import optimize_strategy, walk_forward_optimize, rolling_walk_forward
from src.sensitivity import analyze_sensitivity
from src.bar_permute import get_permutation
from src.multi_asset import run_multi_backtest_on_data
from bt.runner import run_bt


# ── Config ───────────────────────────────────────────────────
SHORT_WINDOW = 10
LONG_WINDOW = 20


# ── Report builder ────────────────────────────────────────────


class ReportBuilder:
    """Accumulate per-step results and render a markdown report."""

    def __init__(self, symbol, start_date, end_date, short_window, long_window):
        self.symbol = symbol
        self.start_date = start_date
        self.end_date = end_date
        self.short_window = short_window
        self.long_window = long_window
        self.timestamp = None
        self._sections = {}

    def add(self, step_num, result):
        self._sections[step_num] = result

    def render(self):
        self.timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        lines = self._header()
        for step_num in sorted(self._sections):
            renderer = getattr(self, f"_section_{step_num}", None)
            if renderer:
                lines += renderer(self._sections[step_num])
        lines += ["", "---",
                   f"*Generated by Mizuto backtest pipeline at {self.timestamp}*", ""]
        return "\n".join(lines)

    def _header(self):
        return [
            f"# Backtest Report: {self.symbol}",
            "",
            "| Field | Value |",
            "|-------|-------|",
            f"| Symbol | {self.symbol} |",
            f"| Date Range | {self.start_date} to {self.end_date} |",
            f"| Short Window | {self.short_window} |",
            f"| Long Window | {self.long_window} |",
            f"| Generated | {self.timestamp} |",
            "",
        ]

    def _section_1(self, r):
        tc = r["trade_count"]
        wr = r["wins"] / tc if tc > 0 else 0
        return [
            "## Step 1: Smoke Test", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Total Trades | {tc} |",
            f"| Win Rate | {wr:.2%} |",
            f"| PnL | {r['pnl']:.2f} |",
            f"| Sharpe Ratio | {r['sharpe_ratio']:.2f} |",
            f"| Max Drawdown | {r['max_drawdown_pct']:.2%} |",
            f"| Profit Factor | {r['profit_factor']:.2f} |",
            "",
        ]

    def _section_2(self, rows):
        lines = [
            "## Step 2: Fill Models", "",
            "| Fill Model | PnL | Sharpe | Trades |",
            "|------------|-----|--------|--------|",
        ]
        for row in rows:
            lines.append(f"| {row['fill_model']} | {row['pnl']:.2f} | "
                         f"{row['sharpe_ratio']:.2f} | {row['trade_count']} |")
        lines.append("")
        return lines

    def _section_3(self, rows):
        lines = [
            "## Step 3: Position Sizing", "",
            "| Method | PnL | Sharpe | Trades |",
            "|--------|-----|--------|--------|",
        ]
        for row in rows:
            lines.append(f"| {row['method']} | {row['pnl']:.2f} | "
                         f"{row['sharpe_ratio']:.2f} | {row['trade_count']} |")
        lines.append("")
        return lines

    def _section_4(self, r):
        bp = r["best_params"]
        return [
            "## Step 4: Parameter Optimization", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Best Short Window | {bp.get('short_window', 'N/A')} |",
            f"| Best Long Window | {bp.get('long_window', 'N/A')} |",
            f"| Best Profit Factor | {r['best_score']:.2f} |",
            "",
        ]

    def _section_5(self, r):
        wf = r["walk_forward"]
        rwf = r["rolling_walk_forward"]
        tr = wf["test_result"]
        return [
            "## Step 5: Walk-Forward Validation", "",
            "### Single Window", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Train Params | {wf['train_params']} |",
            f"| Overfit Ratio | {wf['overfit_ratio']:.2f} |",
            f"| Test PnL | {tr['pnl']:.2f} |",
            f"| Test Sharpe | {tr['sharpe_ratio']:.2f} |",
            "",
            "### Rolling Windows", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Windows Completed | {len(rwf['windows'])} |",
            f"| Avg Test Metric | {rwf['aggregate_test_metric']:.4f} |",
            f"| Avg Train Metric | {rwf['aggregate_train_metric']:.4f} |",
            f"| Avg Overfit Ratio | {rwf['aggregate_overfit_ratio']:.2f} |",
            "",
        ]

    def _section_6(self, r):
        lines = [
            "## Step 6: Sensitivity Analysis", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Base Sharpe | {r['base_metric']:.4f} |",
            f"| Overall Stability | {r['overall_stability']:.4f} |",
            "",
            "### Per-Parameter Sensitivity", "",
            "| Parameter | Sensitivity Score |",
            "|-----------|-------------------|",
        ]
        for param, info in r["per_param"].items():
            lines.append(f"| {param} | {info['sensitivity_score']:.4f} |")
        lines.append("")
        return lines

    def _section_7(self, r):
        sig_label = "SIGNIFICANT" if r["significant"] else "NOT significant"
        return [
            "## Step 7: Monte Carlo Permutation Test", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Real Profit Factor | {r['real_profit_factor']:.2f} |",
            f"| Permutations | {r['n_perms']} |",
            f"| Beat Count | {r['beat_count']} |",
            f"| p-value | {r['p_value']:.3f} |",
            f"| Result | {sig_label} |",
            f"| Elapsed | {r['elapsed_seconds']:.1f}s |",
            "",
        ]

    def _section_8(self, r):
        summary_df = r["summary"]
        agg = r["aggregate"]
        cols = list(summary_df.columns)
        lines = [
            "## Step 8: Multi-Asset Test", "",
            "### Per-Symbol Results", "",
            "| " + " | ".join(str(c) for c in cols) + " |",
            "|" + "|".join("--------" for _ in cols) + "|",
        ]
        for _, row in summary_df.iterrows():
            cells = " | ".join(
                f"{v:.2f}" if isinstance(v, float) else str(v)
                for v in row
            )
            lines.append(f"| {cells} |")
        lines += [
            "", "### Aggregate", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Symbols Tested | {agg['symbols_tested']} |",
            f"| Total PnL | {agg['total_pnl']:.2f} |",
            "",
        ]
        return lines

    def _section_9(self, r):
        custom = r["custom"]
        bt = r["bt"]
        return [
            "## Step 9: Cross-Engine Validation", "",
            "| Metric | Custom | backtesting.py |",
            "|--------|--------|----------------|",
            f"| Trades | {custom['trade_count']} | {bt['trade_count']} |",
            f"| Win Rate | {custom['win_rate']:.2%} | {bt['win_rate']:.2%} |",
            "",
        ]

    def _section_10(self, r):
        lines = [
            "## Step 10: Trade Analytics Review", "",
            "| Metric | Value |",
            "|--------|-------|",
            f"| Expectancy | {r['expectancy']:.2f} |",
            f"| Calmar Ratio | {r['calmar_ratio']:.2f} |",
            f"| Profit Factor | {r['profit_factor']:.2f} |",
            f"| Avg Bars Held | {r['avg_bars_held']:.1f} |",
            f"| Consecutive Wins | {r['consecutive_wins']} |",
            f"| Consecutive Losses | {r['consecutive_losses']} |",
            f"| Largest Win | {r['largest_win']:.2f} |",
            f"| Largest Loss | {r['largest_loss']:.2f} |",
            "",
            "### Exit Reasons", "",
            "| Reason | Count |",
            "|--------|-------|",
        ]
        for reason, count in r.get("exit_reason_counts", {}).items():
            lines.append(f"| {reason} | {count} |")
        lines.append("")
        return lines


def write_report(builder, symbol):
    """Write the markdown report to reports/ directory."""
    reports_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "reports")
    os.makedirs(reports_dir, exist_ok=True)

    date_str = datetime.datetime.now().strftime("%Y-%m-%d")
    safe_symbol = symbol.replace("/", "-")
    filepath = os.path.join(reports_dir, f"backtest_{date_str}_{safe_symbol}.md")

    with open(filepath, "w", encoding="utf-8") as f:
        f.write(builder.render())
    return filepath


# ── Steps ─────────────────────────────────────────────────────


def banner(step_num, title):
    print(f"\n{'='*60}")
    print(f"  Step {step_num}: {title}")
    print(f"{'='*60}\n")


def step_1(data):
    """Smoke test — confirm the strategy runs."""
    banner(1, "Smoke Test")
    results = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW)
    tc = results['trade_count']
    wr = results['wins'] / tc if tc > 0 else 0
    print(f"  Total trades:  {tc}")
    print(f"  Win rate:      {wr:.2%}")
    print(f"  PnL:           {results['pnl']:.2f}")
    print(f"  Sharpe:        {results['sharpe_ratio']:.2f}")
    print(f"  Max drawdown:  {results['max_drawdown_pct']:.2%}")
    return results


def step_2(data):
    """Fill models — test execution assumptions."""
    banner(2, "Fill Models")
    fill_results = []
    for fm in ["close", "next_open", "vwap_slippage"]:
        r = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW,
                                 fill_model=fm)
        print(f"  {fm:20s}  PnL={r['pnl']:>10.2f}  Sharpe={r['sharpe_ratio']:>6.2f}  "
              f"Trades={r['trade_count']}")
        fill_results.append({"fill_model": fm, "pnl": r["pnl"],
                             "sharpe_ratio": r["sharpe_ratio"],
                             "trade_count": r["trade_count"]})
    return fill_results


def step_3(data):
    """Position sizing — volatility and rolling std."""
    banner(3, "Position Sizing")

    print("  Volatility sizing:")
    r = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW,
                             position_sizing="volatility",
                             risk_per_trade=0.02,
                             max_portfolio_risk=0.1)
    print(f"    PnL={r['pnl']:.2f}  Sharpe={r['sharpe_ratio']:.2f}  Trades={r['trade_count']}")

    print("  Rolling std sizing:")
    r2 = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW,
                              position_sizing="rolling_std",
                              risk_per_trade=0.02)
    print(f"    PnL={r2['pnl']:.2f}  Sharpe={r2['sharpe_ratio']:.2f}  Trades={r2['trade_count']}")
    return [
        {"method": "volatility", "pnl": r["pnl"],
         "sharpe_ratio": r["sharpe_ratio"], "trade_count": r["trade_count"]},
        {"method": "rolling_std", "pnl": r2["pnl"],
         "sharpe_ratio": r2["sharpe_ratio"], "trade_count": r2["trade_count"]},
    ]


def step_4(data):
    """Optimize — grid search for best parameters."""
    banner(4, "Optimize Parameters")
    best_params, best_score = optimize_strategy(
        data,
        short_window_range=range(3, 15),
        long_window_range=range(10, 50, 5),
        metric="profit_factor",
    )
    print(f"  Best params:       {best_params}")
    print(f"  Best profit factor: {best_score:.2f}")
    return {"best_params": best_params, "best_score": best_score}


def step_5(data):
    """Walk-forward — out-of-sample validation."""
    banner(5, "Walk-Forward Validation")

    print("  Single window:")
    wf = walk_forward_optimize(data, train_ratio=0.7,
                                short_window_range=range(3, 15),
                                long_window_range=range(10, 50, 5))
    print(f"    Train params:  {wf['train_params']}")
    print(f"    Overfit ratio: {wf['overfit_ratio']:.2f}")
    test_r = wf["test_result"]
    print(f"    Test PnL:      {test_r['pnl']:.2f}")
    print(f"    Test Sharpe:   {test_r['sharpe_ratio']:.2f}")

    print("\n  Rolling windows (5):")
    rwf = rolling_walk_forward(data, n_windows=5, train_ratio=0.7,
                                short_window_range=range(3, 15),
                                long_window_range=range(10, 50, 5))
    print(f"    Windows completed: {len(rwf['windows'])}")
    print(f"    Avg test metric:   {rwf['aggregate_test_metric']:.4f}")
    print(f"    Avg train metric:  {rwf['aggregate_train_metric']:.4f}")
    print(f"    Avg overfit ratio: {rwf['aggregate_overfit_ratio']:.2f}")
    return {"walk_forward": wf, "rolling_walk_forward": rwf}


def step_6(data):
    """Sensitivity — how fragile are the parameters?"""
    banner(6, "Sensitivity Analysis")
    report = analyze_sensitivity(
        data,
        base_params={"short_window": SHORT_WINDOW, "long_window": LONG_WINDOW},
        variation_pct=0.20,
        metric="sharpe_ratio",
    )
    print(f"  Overall stability: {report['overall_stability']:.4f}")
    print(f"  Base Sharpe:       {report['base_metric']:.4f}")
    print()
    for param, info in report["per_param"].items():
        print(f"    {param:20s}  sensitivity={info['sensitivity_score']:.4f}")
    return report


def step_7(data, n_perms=1000):
    """MCPT — is the edge statistically significant?"""
    banner(7, f"Monte Carlo Permutation Test ({n_perms} permutations)")

    real = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW,
                                quiet=True)
    real_pf = real["profit_factor"]
    print(f"  Real profit factor: {real_pf:.2f}")
    print(f"  Running {n_perms} permutations...", end=" ", flush=True)

    start = time.time()
    beat_count = 0
    for i in range(n_perms):
        perm_data = get_permutation(data, seed=i)
        perm_r = run_backtest_on_data(perm_data, short_window=SHORT_WINDOW,
                                       long_window=LONG_WINDOW, quiet=True)
        if real_pf > perm_r["profit_factor"]:
            beat_count += 1

    elapsed = time.time() - start
    p_value = 1 - (beat_count / n_perms)
    sig = "SIGNIFICANT" if p_value < 0.05 else "NOT significant"
    print(f"done ({elapsed:.1f}s)")
    print(f"  p-value: {p_value:.3f} ({sig})")
    return {"real_profit_factor": real_pf, "p_value": p_value,
            "beat_count": beat_count, "n_perms": n_perms,
            "significant": p_value < 0.05, "elapsed_seconds": elapsed}


def step_8(start_date, end_date):
    """Multi-asset — does it generalize?"""
    banner(8, "Multi-Asset Test")
    symbols = ["BTC-USD", "ETH-USD", "SOL-USD"]
    print(f"  Downloading {', '.join(symbols)}...")
    datasets = {}
    for sym in symbols:
        datasets[sym] = yf.download(sym, start=start_date, end=end_date, progress=False)

    multi = run_multi_backtest_on_data(datasets, short_window=SHORT_WINDOW,
                                       long_window=LONG_WINDOW)
    print(f"\n  Summary:")
    print(multi["summary"].to_string(index=True))
    agg = multi["aggregate"]
    print(f"\n  Aggregate PnL:      {agg['total_pnl']:.2f}")
    print(f"  Symbols tested:     {agg['symbols_tested']}")
    return multi


def step_9(data):
    """Cross-engine — custom vs backtesting.py."""
    banner(9, "Cross-Engine Validation")

    custom = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW)
    bt_stats = run_bt("ma_crossover", data=data,
                       short_window=SHORT_WINDOW, long_window=LONG_WINDOW)

    tc = custom['trade_count']
    wr = custom['wins'] / tc if tc > 0 else 0
    print(f"  {'':20s} {'Custom':>10s} {'bt.py':>10s}")
    print(f"  {'Trades':20s} {tc:>10} {bt_stats['# Trades']:>10}")
    print(f"  {'Win rate':20s} {wr:>10.2%} {bt_stats['Win Rate [%]']/100:>10.2%}")
    return {
        "custom": {"trade_count": tc, "win_rate": wr},
        "bt": {"trade_count": int(bt_stats["# Trades"]),
               "win_rate": bt_stats["Win Rate [%]"] / 100},
    }


def step_10(data):
    """Review analytics — detailed trade stats."""
    banner(10, "Trade Analytics Review")
    r = run_backtest_on_data(data, short_window=SHORT_WINDOW, long_window=LONG_WINDOW,
                             fill_model="next_open",
                             position_sizing="volatility",
                             risk_per_trade=0.02,
                             max_portfolio_risk=0.1)

    print(f"  Expectancy:          {r['expectancy']:.2f}")
    print(f"  Calmar ratio:        {r['calmar_ratio']:.2f}")
    print(f"  Profit factor:       {r['profit_factor']:.2f}")
    print(f"  Avg bars held:       {r['avg_bars_held']:.1f}")
    print(f"  Consecutive wins:    {r['consecutive_wins']}")
    print(f"  Consecutive losses:  {r['consecutive_losses']}")
    print(f"  Largest win:         {r['largest_win']:.2f}")
    print(f"  Largest loss:        {r['largest_loss']:.2f}")
    print(f"  Exit reasons:        {r['exit_reason_counts']}")
    return r


def main():
    parser = argparse.ArgumentParser(description="Mizuto comprehensive backtest pipeline")
    parser.add_argument("--step", nargs="+", type=int, default=None,
                        help="Run specific steps (e.g. --step 1 2 3). Default: all")
    parser.add_argument("--symbol", default="BTC-USD", help="yfinance symbol (default: BTC-USD)")
    parser.add_argument("--start", default="2023-01-01", help="Start date (default: 2023-01-01)")
    parser.add_argument("--end", default="2024-01-01", help="End date (default: 2024-01-01)")
    parser.add_argument("--perms", type=int, default=1000,
                        help="MCPT permutations (default: 1000, use 100 for quick test)")
    parser.add_argument("--no-report", action="store_true",
                        help="Skip writing the markdown report")
    args = parser.parse_args()

    steps = args.step or list(range(1, 11))

    print(f"Downloading {args.symbol} ({args.start} to {args.end})...")
    data = yf.download(args.symbol, start=args.start, end=args.end, progress=False)
    if data.empty:
        print("ERROR: No data downloaded. Check symbol and date range.")
        sys.exit(1)
    print(f"Got {len(data)} bars.\n")

    report = ReportBuilder(
        symbol=args.symbol,
        start_date=args.start,
        end_date=args.end,
        short_window=SHORT_WINDOW,
        long_window=LONG_WINDOW,
    )

    runners = {
        1: lambda: step_1(data),
        2: lambda: step_2(data),
        3: lambda: step_3(data),
        4: lambda: step_4(data),
        5: lambda: step_5(data),
        6: lambda: step_6(data),
        7: lambda: step_7(data, n_perms=args.perms),
        8: lambda: step_8(args.start, args.end),
        9: lambda: step_9(data),
        10: lambda: step_10(data),
    }

    for s in steps:
        if s in runners:
            result = runners[s]()
            if result is not None:
                report.add(s, result)
        else:
            print(f"Unknown step {s}, skipping.")

    print(f"\n{'='*60}")
    print("  Pipeline complete.")
    print(f"{'='*60}")

    if not args.no_report and report._sections:
        path = write_report(report, args.symbol)
        print(f"\n  Report written to: {path}")


if __name__ == "__main__":
    main()
